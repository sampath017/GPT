{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_M = 1e6 \n",
    "one_B = 1e9\n",
    "\n",
    "max_lr = 6e-4\n",
    "min_lr = max_lr*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_tokens = 375*one_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "715.2557373046875"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2**19\n",
    "max_steps = 17167\n",
    "warmup_steps = warmup_tokens / batch_size\n",
    "warmup_steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m train_step = \u001b[32m10\u001b[39m\n\u001b[32m      3\u001b[39m decay_ratio = (train_step - warmup_steps) / (\n\u001b[32m      4\u001b[39m    max_steps - warmup_steps)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[32m0\u001b[39m <= decay_ratio <= \u001b[32m1\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_step = 10\n",
    "\n",
    "decay_ratio = (train_step - warmup_steps) / (\n",
    "   max_steps - warmup_steps)\n",
    "assert 0 <= decay_ratio <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we need CUDA for DDP so falling back to CPU\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import settings as s\n",
    "from pathlib import Path\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F \n",
    "from hellaswag import evaluate\n",
    "from transformers import GPT2LMHeadModel\n",
    "from utils import ModelSummary\n",
    "from models import GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 475.03 MB\n",
      "Trainable parameters: 124.53M\n",
      "Non-trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "model = GPT()\n",
    "ModelSummary.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70ac764a24d4f4d9dbd23908288d596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ebceedf6654636bc36f3425e9b89cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414a54d25a494fd9b29a40307bbd4d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 486.70 MB\n",
      "Trainable parameters: 124.44M\n",
      "Non-trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\n",
    "    \"gpt2\", cache_dir=s.logs_path).to(s.device)\n",
    "ModelSummary.summary(gpt2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = gpt2_model.state_dict()\n",
    "embedding_weights = sd[\"transformer.wte.weight\"]\n",
    "embedding_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU cost estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572.2333333333332"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A100_cost = ((17167 * 1.2) / 3600) * 100\n",
    "A100_cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.722333333333332"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((17167 * 1.2) / 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.305833333333334"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((17167 * 3) / 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429.175"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A6000_cost = ((17167 * 3) / 3600) * 30\n",
    "A6000_cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(gpt2_xl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ind': 4,\n",
       " 'activity_label': 'Removing ice from car',\n",
       " 'ctx_a': 'Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles.',\n",
       " 'ctx_b': 'then',\n",
       " 'ctx': 'Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles. then',\n",
       " 'split': 'train',\n",
       " 'split_type': 'indomain',\n",
       " 'label': 3,\n",
       " 'endings': [', the man adds wax to the windshield and cuts it.',\n",
       "  ', a person board a ski lift, while two men supporting the head of the person wearing winter clothes snow as the we girls sled.',\n",
       "  ', the man puts on a christmas coat, knitted with netting.',\n",
       "  ', the man continues removing the snow on his car.'],\n",
       " 'source_id': 'activitynet~v_-1IBHYS3L-Y'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_jsonl(file_path):\n",
    "    file_path = Path(file_path)\n",
    "    with file_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f if line.strip()]\n",
    "    \n",
    "train_data = read_jsonl(s.data_root_path / \"hellaswag/hellaswag_train.jsonl\")\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 486.70 MB\n",
      "Trainable parameters: 124.44M\n",
      "Non-trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\n",
    "    \"gpt2\", cache_dir=s.logs_path).to(s.device)\n",
    "summary = ModelSummary(model)\n",
    "summary.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A female chef in white uniform shows a stack of baking pans in a large kitchen presenting them. The pans are filled with pastries and loaded into the oven. a knife\n",
      "1: is seen moving on a board and cutting out its contents.\n",
      "2: hits the peeled cheesecake, followed by sliced custard and still cooked ice cream.\n",
      "3: etches a shape into the inside of the baked pans.\n",
      "4: is used to cut cylinder shaped dough into rounds.\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def print_example(row):\n",
    "    question = row[\"ctx\"]\n",
    "    options = row[\"endings\"]\n",
    "    correct_option = row[\"label\"]\n",
    "\n",
    "    print(question)\n",
    "    for i, option in enumerate(options, start=1):\n",
    "        print(f\"{i}: {option}\")\n",
    "\n",
    "    print(correct_option)\n",
    "\n",
    "row = train_data[2]\n",
    "print_example(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_example(example):\n",
    "    \"\"\"\n",
    "    Given the example as a dictionary, render it as three torch tensors:\n",
    "    - tokens (the tokens of context + completion, of size 4xN, as there are always 4 candidates)\n",
    "    - mask (is 1 in the region of the candidate completion, where we evaluate likelihoods)\n",
    "    - label (the index of the correct completion, which we hope has the highest likelihood)\n",
    "    \"\"\"\n",
    "    ctx = example[\"ctx\"]\n",
    "    label = example[\"label\"]\n",
    "    endings = example[\"endings\"]\n",
    "\n",
    "    # data needed to reproduce this eval on the C size\n",
    "    data = {\n",
    "        \"label\": label,\n",
    "        \"ctx_tokens\": None,\n",
    "        \"ending_tokens\": [],\n",
    "    }\n",
    "\n",
    "    # gather up all the tokens\n",
    "    ctx_tokens = s.enc.encode(ctx)\n",
    "    data[\"ctx_tokens\"] = ctx_tokens\n",
    "    tok_rows = []\n",
    "    mask_rows = []\n",
    "    for end in endings:\n",
    "        # note: prepending \" \" because GPT-2 tokenizer\n",
    "        end_tokens = s.enc.encode(\" \" + end)\n",
    "        tok_rows.append(ctx_tokens + end_tokens)\n",
    "        mask_rows.append([0]*len(ctx_tokens) + [1]*len(end_tokens))\n",
    "        data[\"ending_tokens\"].append(end_tokens)\n",
    "\n",
    "    # have to be careful during the collation because the number of tokens in each row can differ\n",
    "    max_len = max(len(row) for row in tok_rows)\n",
    "    tokens = torch.zeros((4, max_len), dtype=torch.long)\n",
    "    mask = torch.zeros((4, max_len), dtype=torch.long)\n",
    "    for i, (tok_row, mask_row) in enumerate(zip(tok_rows, mask_rows)):\n",
    "        tokens[i, :len(tok_row)] = torch.tensor(tok_row)\n",
    "        mask[i, :len(mask_row)] = torch.tensor(mask_row)\n",
    "\n",
    "    return data, tokens, mask, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 51])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, tokens, mask, label = render_example(train_data[2])\n",
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A female chef in white uniform shows a stack of baking pans in a large kitchen presenting them. The pans are filled with pastries and loaded into the oven. a knife is seen moving on a board and cutting out its contents.!!!!!\n",
      "A female chef in white uniform shows a stack of baking pans in a large kitchen presenting them. The pans are filled with pastries and loaded into the oven. a knife hits the peeled cheesecake, followed by sliced custard and still cooked ice cream.\n",
      "A female chef in white uniform shows a stack of baking pans in a large kitchen presenting them. The pans are filled with pastries and loaded into the oven. a knife etches a shape into the inside of the baked pans.!!!!!\n",
      "A female chef in white uniform shows a stack of baking pans in a large kitchen presenting them. The pans are filled with pastries and loaded into the oven. a knife is used to cut cylinder shaped dough into rounds.!!!!!!!\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\"\"\"\"\"\"\"\"\"\"\"!!!!!\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\"\"\"\"\"\"\"\"\"\"\"!!!!!\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\"\"\"\"\"\"\"\"\"!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "for t in tokens:\n",
    "    print(s.enc.decode(t.tolist()))\n",
    "\n",
    "for t in mask:\n",
    "    print(s.enc.decode(t.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 51, 50257])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the logits\n",
    "tokens = tokens.to(s.device)\n",
    "logits = model(tokens).logits\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 50, 50257])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tokens[..., :-1]\n",
    "y = tokens[..., 1:]\n",
    "\n",
    "logits = model(x).logits\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.CausalLMOutputWithCrossAttentions"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model(x))\n",
    "2494/10042\n",
    "2456/10042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_logits = logits.reshape(-1, logits.shape[-1])\n",
    "flat_y = y.reshape(-1)\n",
    "shift_losses = F.cross_entropy(\n",
    "    flat_logits, flat_y, reduction='none')\n",
    "\n",
    "shift_losses = shift_losses.reshape(y.shape[0], -1)\n",
    "\n",
    "# now get the average loss just for the completion region (where mask == 1), in each row\n",
    "# we must shift mask, so we start at the last prompt token\n",
    "shift_mask = mask[..., 1:]\n",
    "masked_shift_losses = shift_losses * shift_mask\n",
    "\n",
    "# sum and divide by the number of 1s in the mask\n",
    "sum_loss = masked_shift_losses.sum(dim=1)\n",
    "avg_loss = sum_loss / shift_mask.sum(dim=1)\n",
    "\n",
    "avg_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HellaSwag accuracy: 2962/10042=0.2950\n"
     ]
    }
   ],
   "source": [
    "from hellaswag import iterate_examples, get_most_likely_row\n",
    "\n",
    "# once in a while evaluate hellaswag\n",
    "num_correct_norm = 0\n",
    "num_total = 0\n",
    "for i, example in enumerate(iterate_examples(\"val\")):\n",
    "    # only process examples where i % ddp_world_size == ddp_rank\n",
    "    if i % s.ddp_world_size != s.ddp_local_rank:\n",
    "        continue\n",
    "    # render the example into tokens and labels\n",
    "    _, tokens, mask, label = render_example(example)\n",
    "    tokens = tokens.to(s.device)\n",
    "    mask = mask.to(s.device)\n",
    "    x = tokens[..., :-1]\n",
    "    y = tokens[..., 1:]\n",
    "\n",
    "    # get the logits\n",
    "    with torch.no_grad():\n",
    "        with torch.autocast(device_type=s.device, dtype=torch.bfloat16):\n",
    "            logits = model(x).logits\n",
    "        pred_norm = get_most_likely_row(logits, y, mask)\n",
    "    num_total += 1\n",
    "    num_correct_norm += int(pred_norm == label)\n",
    "\n",
    "hellaswag_acc = num_correct_norm / num_total\n",
    "if s.ddp_master_process:\n",
    "    print(\n",
    "        f\"HellaSwag accuracy: {num_correct_norm}/{num_total}={hellaswag_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
